{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665e0d40",
   "metadata": {},
   "source": [
    "# Databases\n",
    "\n",
    "\n",
    ":::{important}\n",
    "⚠️ Under Construction !\n",
    ":::\n",
    "\n",
    "\n",
    "This tutorial will cover the basics of building a database. We will test a relational database, taking the data from a pandas dataframe. We will test a non-relational database using the first database and adding documents to it.\n",
    "\n",
    "The data base we will build is a collection of earthquake events metadata and seismograms together. Both can be two separate relational databases. We will benchmark performance on metadata manipulations.\n",
    "\n",
    "You can find help here: http://swcarpentry.github.io/sql-novice-survey/10-prog/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5224d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c8d32",
   "metadata": {},
   "source": [
    "## 1. Preparing the data\n",
    "We will use the metadata of the seismic stations as a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439854e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from math import cos, sin, pi, sqrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb5a58-6167-42cb-b7db-f0d4ac84bd0c",
   "metadata": {},
   "source": [
    "We will use the Northern California Earthquake Data Center stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3441c-1aaa-48f4-825f-8030035bf77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the station information\n",
    "url = 'http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day'\n",
    "s = requests.get(url).content\n",
    "data = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None, skiprows=2, sep='\\s+', usecols=list(range(0, 13)))\n",
    "data.columns = ['station', 'network', 'channel', 'location', 'rate', 'start_time', 'end_time', 'latitude', 'longitude', 'elevation', 'depth', 'dip', 'azimuth']\n",
    "data.to_csv('ncedc_stations.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a331d8c-e7f8-4adb-8318-8b351cd692d1",
   "metadata": {},
   "source": [
    "We will download earthquake waveforms from Ariane's earthquake catalog of repeating earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c822ec",
   "metadata": {},
   "source": [
    "## 2. Relational database: SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b4615-84f9-459f-8119-dff1dc3f8ff2",
   "metadata": {},
   "source": [
    "This is an example on how to dump a pandas dataframe into a SQL database. But honestly, i can't seem to figure out how to query it afterwards!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e61243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///ncedc_stations_sql.db',echo=False)\n",
    "db_sql = engine.connect()\n",
    "data_sql=data.to_sql('data_db_sql',db_sql,index=False,\\\n",
    "               if_exists='append')\n",
    "data_db_sql=engine.execute(\"SELECT * FROM data_db_sql\")\n",
    "\n",
    "# I think that is how things work, but i can't seem to query the database..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7ec3c",
   "metadata": {},
   "source": [
    "## 3. Nonrelational document database: MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23256356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "mongo_client = MongoClient('localhost', 27017)# this will create a local db (default is cloud service)\n",
    "\n",
    "mydb=mongo_client['NCEDC']\n",
    "\n",
    "doc = mydb['stations']\n",
    "#data.reset_index(inplace=True)\n",
    "\n",
    "data_dict = data.to_dict(\"records\")\n",
    "# Insert collection\n",
    "\n",
    "doc.insert_many(data_dict)\n",
    "print(mydb.stations.find_one())\n",
    "print(\"   \")\n",
    "print(doc)\n",
    "\n",
    "data.to_json('ncedc_stations_mongo.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b17c0-ef01-44c3-9a83-42e07f2c19e4",
   "metadata": {},
   "source": [
    "Now the advantage of non-relational databases and document stores are that we can also add other files/data types into the database. We will add the earthquake catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dfcbe-c9fe-4028-9382-123dfacbddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "namefile = 'catalog_2007_2009.pkl'\n",
    "tbegin = datetime(2007, 9, 25, 0, 0, 0)\n",
    "tend = datetime(2009, 5, 14, 0, 0, 0)\n",
    "dt = 10.0\n",
    "thresh1 = 1.4\n",
    "thresh2 = 1.9\n",
    "df1 = pickle.load(open(namefile, 'rb'))\n",
    "df1 = df1[['year', 'month', 'day', 'hour', 'minute', 'second', 'cc', 'nchannel']]\n",
    "df1 = df1.astype({'year': int, 'month': int, 'day': int, 'hour': int, 'minute': int, 'second': float, 'cc': float, 'nchannel': int})\n",
    "date = pd.to_datetime(df1.drop(columns=['cc', 'nchannel']))\n",
    "df1['date'] = date\n",
    "df1 = df1[(df1['date'] >= tbegin) & (df1['date'] <= tend)]\n",
    "df1_filter = df1.loc[df1['cc'] * df1['nchannel'] >= thresh1]\n",
    "data_dict = df1_filter.to_dict(\"records\")\n",
    "\n",
    "\n",
    "# doc = mydb['stations']\n",
    "doc2 = mydb['earthquakes']\n",
    "doc2.insert_many(data_dict)\n",
    "\n",
    "print(mydb.earthquakes.find_one())\n",
    "print(doc)\n",
    "print(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ab110",
   "metadata": {},
   "source": [
    "## 4. Benchmarking exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca4f62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# from sqlalchemy import desc, select\n",
    "\n",
    "# sorting by station nam\n",
    "%time\n",
    "data.sort_values(\"station\") # sort the pandas\n",
    "print('Pandas sorted')\n",
    "\n",
    "%time\n",
    "mydb[\"stations\"].find().sort(\"station\") # sort the mongoDB\n",
    "print('Mongo sorted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by date of the earthquakes\n",
    "%time\n",
    "df1_filter.sort_values(\"date\") # sort the pandas\n",
    "print('Pandas sorted')\n",
    "\n",
    "%time\n",
    "mydb[\"earthquakes\"].find().sort(\"date\") # sort the mongoDB\n",
    "print('Mongo sorted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d983af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by\n",
    "%time\n",
    "data.groupby('station').station.count()\n",
    "print('Pandas group by stations')\n",
    "\n",
    "%time\n",
    "mydb[\"stations\"].aggregate([\\\n",
    "         {\"$unwind\": \"$station\"},\\\n",
    "         {\"$group\": {\"_id\": \"$station\", \"count\": {\"$sum\": 1}}},\\\n",
    "  ])\n",
    "print('Mongo group by station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87cfbd-9d83-44bf-8205-266f8a13fe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('madrona')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c2df93b363d800c8a9b94963221f1be1d8deaf6a76f83b6b9a486ad05d69583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
