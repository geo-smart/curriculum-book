
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4.1 Multi Layer Perceptrons &#8212; ML Geo Curriculum</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4.2 Convolutional Neural Networks" href="week9_cnn.html" />
    <link rel="prev" title="3.2 Logistic regression" href="../Chapter3-MachineLearning/logistic_regression.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/GeoSMART_logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">ML Geo Curriculum</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../about_this_book/about_this_book.html">
                    Machine Learning in the Geosciences
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About this Book
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://geo-smart.github.io/index.html">
   Geosmart website
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about_this_book/acknowledgements.html">
   Acknowlegments
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 1 - Open Source Ecosystem with Python
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1-GettingStarted/readme.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1-GettingStarted/1.1_python_environment.html">
   1.1 Python Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1-GettingStarted/1.2_jupyter_environment.html">
   1.2 Jupyter Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1-GettingStarted/1.3_version_control_git.html">
   1.3 Version Control &amp; GitHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1-GettingStarted/1.4_computational_environments.html">
   1.4 Computing Environments
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 2 - Data Manipulation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.1_Data_Definitions.html">
   2.1 Data Definitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.2_Numpy_arrays.html">
   2.2 Numpy Arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.3_pandas_rendered.html">
   2.3 Pandas, Basic Mapping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.4_xarrays.html">
   2.4 Xarrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.5_data_formats_rendered.html">
   2.5 Data Formats
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.6_resampling.html">
   2.6 Resampling Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.8_feature_engineering.html">
   2.8 Feature engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter2-DataManipulation/2.9_pca.html">
   2.9 Dimensionality Reduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 3 - Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter3-MachineLearning/3.1_kmeans.html">
   3.1 Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter3-MachineLearning/logistic_regression.html">
   3.2 Logistic regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 4 - Deep Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4.1 Multi Layer Perceptrons
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="week9_cnn.html">
   4.2 Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_LeNet.html">
   4.3 Convolutional neural networks with PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="autoen.html">
   4.4 Auto-encoders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ModelTraining.html">
   4.5 Training Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="week9_training.html">
   4.6 Deep Neural Networks and their training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="neural_networks_PyTorch.html">
   4.7 Using PyTorch to build, train, and use neural networks: A short introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 5 - Model Evaluation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter5-ModelEvaluation/week7_classification_model_fit.html">
   Classification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 6 - Workflow Management and Reproducibility
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter6-ModelWorkflows/readme.html">
   This chapter focuces on model workflow and ML reproducibility
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 7- Introduction to Cloud Computing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/cloudmaven">
   Browser Access to Cloud Instances
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/Denolle-Lab/azure">
   Terraform Access to Cloud Instances
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://tljh.jupyter.org/en/latest/">
   Cloud Provider ML Jupyterhubs
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/glossary.html">
   Glossaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/geo-smart/curriculum-book/main?urlpath=lab/tree/book/Chapter4-DeepLearning/MultiLayerPerceptron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/geo-smart/curriculum-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/curriculum-book/issues/new?title=Issue%20on%20page%20%2FChapter4-DeepLearning/MultiLayerPerceptron.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/curriculum-book/edit/main/book/Chapter4-DeepLearning/MultiLayerPerceptron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/Chapter4-DeepLearning/MultiLayerPerceptron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activation-functions">
   1. Activation Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#typical-mlp-structures">
   2. Typical MLP structures
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-neural-networks">
   2. Training Neural Networks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mlp-in-keras">
   3. MLP in Keras
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-the-optimizer">
     Define the optimizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compile-the-model">
     Compile the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-evaluate-the-model">
     Train and evaluate the model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#saving-and-restoring-a-model">
   4. Saving and restoring a model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fine-tuning-of-neural-networks-hyperparameters">
   5. Fine-tuning of Neural Networks Hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mlp-with-scikit-learn">
     MLP with scikit learn
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>4.1 Multi Layer Perceptrons</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activation-functions">
   1. Activation Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#typical-mlp-structures">
   2. Typical MLP structures
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-neural-networks">
   2. Training Neural Networks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mlp-in-keras">
   3. MLP in Keras
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-the-optimizer">
     Define the optimizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compile-the-model">
     Compile the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-evaluate-the-model">
     Train and evaluate the model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#saving-and-restoring-a-model">
   4. Saving and restoring a model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fine-tuning-of-neural-networks-hyperparameters">
   5. Fine-tuning of Neural Networks Hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mlp-with-scikit-learn">
     MLP with scikit learn
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="multi-layer-perceptrons">
<h1>4.1 Multi Layer Perceptrons<a class="headerlink" href="#multi-layer-perceptrons" title="Permalink to this headline">#</a></h1>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>⚠️ Under Construction !</p>
</div>
<p>The linear model cannot fit all of the data. We can introduce non linearity by including hidden layers that connect each neuron with each other.</p>
<p><img alt="Multi Layer Perceptron" src="../_images/mlps.svg" />
A MLP with a fully connected hidden layer. It has 4 inputs, 3 ouputs, 5 hidden units.</p>
<p>MLPs can capture complex interactions among our inputs via their hidden neurons, which depend on the values of each of the inputs. We can model any function, so they are great universal approximators.</p>
<p>A <strong>fully connected</strong> or <strong>dense</strong> layer is one where all neurons are connected to all neurons from the previous layer. The output of a fully connected layer is:
<span class="math notranslate nohighlight">\(h(\mathbf{x}) = \phi (\mathbf{W} \mathbf{x} + \mathbf{b})\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(\phi()\)</span> is the activation function, <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> is the bias vector, <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> is the weight vectors, <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is the feature vector. Training a MLP is finding the weights and biases that best</p>
<section id="activation-functions">
<h2>1. Activation Functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">#</a></h2>
<p>Activation functions decide whether a neuron should be activated or not by calculating the weighted sum and further adding bias with it. We will review the activation functions:</p>
<ul class="simple">
<li><p><strong>Rectified linear unit (ReLU)</strong>
ReLU provides a very simple nonlinear transformation.
<span class="math notranslate nohighlight">\(ReLU(x)=max(x,0).\)</span>
The reason for using ReLU is that its derivatives are particularly well behaved: either they vanish or they just let the argument through. This makes optimization better behaved. These are the most popular activation functions, easier to implement and to train.</p></li>
<li><p><strong>Sigmoid Function</strong>
The sigmoid function transforms its inputs, for which values lie in the real domain, to outputs that lie on the interval (0, 1).
<span class="math notranslate nohighlight">\(\sigma(x) = \frac{1}{1+\exp(-x)}\)</span>
The sigmoid function is a smooth, “S-shaped”, differentiable approximation to a thresholding unit. Sigmoids are still widely used as activation functions on the output units, when we want to interpret the outputs as probabilities for binary classification problems.</p></li>
<li><p><strong>Tanh Function</strong>
The yperbolic tangent function is happy middle between the sigmoid and the ReLU as it is slightly more linear near zero.
<span class="math notranslate nohighlight">\(\tanh(x) = 2 \sigma(2x) -1\)</span>
Tanh is also “S-shaped”</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sigm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="c1"># define the sigmoid function</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="c1"># define the Rectified Linear Unit function</span>
    <span class="k">return</span>   <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>


<span class="n">s</span> <span class="o">=</span> <span class="n">sigm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span><span class="s1">&#39;ReLu&#39;</span><span class="p">,</span><span class="s1">&#39;TanH&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;activation functions&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;activation functions&#39;)
</pre></div>
</div>
<img alt="../_images/MultiLayerPerceptron_1_1.png" src="../_images/MultiLayerPerceptron_1_1.png" />
</div>
</div>
</section>
<section id="typical-mlp-structures">
<h2>2. Typical MLP structures<a class="headerlink" href="#typical-mlp-structures" title="Permalink to this headline">#</a></h2>
<p>A <strong>Regression MLP</strong> outputs scalar values, the number of output neurons is the number of values and the number of the ouput dimensions. For instance, to ouput a 2D geospatial coordinates on a map, you may need to ouput 2 values in 2 output neurons: latitudes and longitudes. For any real scalar as output values, the output layer is a normal layer of neurons. To constrain the value of the outputs, you can add an activation function in the output layer: use a <em>ReLU</em> or a <em>softplus</em> function for <strong>strictly positive</strong> values and a <em>sigmoid</em> or <em>tanh</em> activation function for <strong>bounded values</strong> between 0 (or -1) to 1 by scaling the output. A simple representation of a regression MLP is show in the first figure.</p>
<p><img alt="Regression MLP" src="../_images/MLPReg.png" /></p>
<p>A <strong>Classification MLP</strong> outputs the propability of the positive class, a scalar value between 0 and 1. Use a <em>ReLU</em> or a <em>softplus</em> as an activation function in the output layer.</p>
<p><img alt="Classification MLP" src="../_images/MLPClass.png" /></p>
</section>
<section id="training-neural-networks">
<h2>2. Training Neural Networks<a class="headerlink" href="#training-neural-networks" title="Permalink to this headline">#</a></h2>
<p>Training starts by handling a mini-batch of several (but not all) instances. Each time of training is performed is called an <strong>epoch</strong>.</p>
<p>The <em>forward pass</em> sends the mini-batch from the input layer to the hidden layers. <em>Forward propagation</em> sequentially calculates and stores intermediate variables within the computational graph defined by the neural network. It proceeds from the input to the output layer and makes prediction.</p>
<p>Next, the algorithm measures the error using a loss function and calculate how much each of the ouput connection contributed to the error.</p>
<p><em>Backpropagation</em> sequentially calculates and stores the gradients of intermediate variables and parameters within the neural network in the reversed order. backpropagation is merely an application of chain rule to find the derivatives of cost with respect to any variable in the nested equation. The derivative of cost with respect to any weight in the network, we simply is the multiplication of the corresponding layer’s error times its input. Therefore in training, one has to save each layer input in addition to the weights, and therefore requires additional memory compared to a simple forward pass (prediction).</p>
<p>The algorithm then performs Gradient Descent to update the weights.</p>
<p><strong>Drop out</strong>
One additional mitigation against overfitting is to use dropout layers during training. During training, the Dropout layer will randomly drop out outputs of the previous layer (or equivalently, the inputs to the subsequent layer) according to the specified dropout probability. Dropout is only used during training.</p>
<p><img alt="Multi Layer Perceptron" src="../_images/dropout2.svg" /></p>
<p>a <strong>Sequential</strong> model is a single branch MLP.</p>
</section>
<section id="mlp-in-keras">
<h2>3. MLP in Keras<a class="headerlink" href="#mlp-in-keras" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the fashion MNIST data. it&#39;s boring, but it works!</span>

<span class="n">fashion_mnist</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span>
<span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;tshirt&quot;</span><span class="p">,</span><span class="s2">&quot;trousers&quot;</span><span class="p">,</span><span class="s2">&quot;pullover&quot;</span><span class="p">,</span><span class="s2">&quot;dress&quot;</span><span class="p">,</span><span class="s2">&quot;coat&quot;</span><span class="p">,</span><span class="s2">&quot;sandal&quot;</span><span class="p">,</span><span class="s2">&quot;shirt&quot;</span><span class="p">,</span><span class="s2">&quot;sneaker&quot;</span><span class="p">,</span><span class="s2">&quot;bag&quot;</span><span class="p">,</span><span class="s2">&quot;boot&quot;</span><span class="p">]</span>
<span class="c1">#there are 10 classes in the data sets</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">[</span><span class="mi">1</span><span class="p">,:,:]),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">[</span><span class="mi">1</span><span class="p">,:,:]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(60000, 28, 28)
uint8
0 255
</pre></div>
</div>
</div>
</div>
<p>The data set is already split between training and testing sets. But there is not validation set yet. We also will need to scale the data to use GD. The values of the data range between 0 and 255. So we can just normalize them to 255 for scaling. We will first do a crude split between training and validating.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_val</span><span class="p">,</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_full</span><span class="p">[:</span><span class="mi">5000</span><span class="p">]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span><span class="n">X_train_full</span><span class="p">[</span><span class="mi">5000</span><span class="p">:]</span><span class="o">/</span><span class="mf">255.0</span>
<span class="n">y_val</span><span class="p">,</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train_full</span><span class="p">[:</span><span class="mi">5000</span><span class="p">],</span><span class="n">y_train_full</span><span class="p">[</span><span class="mi">5000</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s create a Classification MLP for a multi-class problem. We use a flatten input layer to turn the 28x28 matrix into a 1D vector. The</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">]))</span> <span class="c1"># reshape the 2D matrix into a 1D vector, without modifying the values</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span> <span class="c1"># single dense layer, downsampling from input layer to this year from 784 points to 300.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span> <span class="c1"># 100 neurons</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span> <span class="c1"># output layer, 10 neurons since there are 10 classes.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span> <span class="p">[</span>
<span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">]),</span> <span class="c1"># reshape the 2D matrix into a 1D vector, without modifying the values</span>
<span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span> <span class="c1"># single dense layer, downsampling from input layer to this year from 784 points to 300.</span>
<span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span> <span class="c1"># 100 neurons</span>
<span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span> <span class="p">])</span> <span class="c1"># output layer, 10 neurons since there are 10 classes.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_2 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 300)               235500    
_________________________________________________________________
dense_7 (Dense)              (None, 100)               30100     
_________________________________________________________________
dense_8 (Dense)              (None, 10)                1010      
=================================================================
Total params: 266,610
Trainable params: 266,610
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
</div>
</div>
<p>Get the properties of each layer</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">L1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">L1</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="n">w</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">L1</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;initialized weights&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;initialized biases&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dense_6
initialized weights
[[-0.00814538 -0.03027174 -0.07386035 ...  0.0458733   0.06985845
  -0.025172  ]
 [ 0.03256713 -0.06009654 -0.03741575 ... -0.06845641  0.03898153
  -0.06552993]
 [ 0.02121779 -0.07328574  0.05836841 ... -0.05685415 -0.06445601
  -0.04741516]
 ...
 [ 0.02453244  0.01921134  0.03246373 ...  0.04681103 -0.01296708
  -0.03949266]
 [-0.05003146 -0.02811283  0.02461205 ... -0.00389059 -0.04133076
   0.06003419]
 [ 0.02773331 -0.0580985   0.02884672 ...  0.01298088 -0.06907778
  -0.01312438]]
(784, 300)
initialized biases
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
(300,)
</pre></div>
</div>
</div>
</div>
<section id="define-the-optimizer">
<h3>Define the optimizer<a class="headerlink" href="#define-the-optimizer" title="Permalink to this headline">#</a></h3>
<p>Choose an optimizer to train the algorithm: <a class="reference external" href="https://keras.io/api/optimizers/">https://keras.io/api/optimizers/</a>. Choose hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.005</span><span class="c1"># learning rate lr</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span> <span class="c1"># stochastic gradient descent</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="compile-the-model">
<h3>Compile the model<a class="headerlink" href="#compile-the-model" title="Permalink to this headline">#</a></h3>
<p>Compile the model by setting the loss function, the optimizer to user, and the metrics to use during training and evaluation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
             <span class="n">metrics</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-and-evaluate-the-model">
<h3>Train and evaluate the model<a class="headerlink" href="#train-and-evaluate-the-model" title="Permalink to this headline">#</a></h3>
<p>During the fitting, it may be important to save intermediate steps and maybe revert back to earlier version of the training. For this, we will use <strong>checkpoints</strong> to save the model at regular intervals during the training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">checkpoints_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;my_first_NN_model.h5&quot;</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># with the argument save_best_only, the checkpoint saved will be one that of best performance according to the performance metrics chosen.</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">),</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoints_cb</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1286 - accuracy: 0.9507 - val_loss: 0.4479 - val_accuracy: 0.8920
Epoch 2/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1240 - accuracy: 0.9523 - val_loss: 0.4297 - val_accuracy: 0.8920
Epoch 3/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1215 - accuracy: 0.9534 - val_loss: 0.4163 - val_accuracy: 0.8982
Epoch 4/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1183 - accuracy: 0.9539 - val_loss: 0.4248 - val_accuracy: 0.8896
Epoch 5/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1169 - accuracy: 0.9553 - val_loss: 0.4406 - val_accuracy: 0.8952
Epoch 6/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1127 - accuracy: 0.9569 - val_loss: 0.5093 - val_accuracy: 0.8914
Epoch 7/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1144 - accuracy: 0.9565 - val_loss: 0.4738 - val_accuracy: 0.8954
Epoch 8/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1093 - accuracy: 0.9578 - val_loss: 0.4926 - val_accuracy: 0.8910
Epoch 9/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1077 - accuracy: 0.9591 - val_loss: 0.4646 - val_accuracy: 0.8946
Epoch 10/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1104 - accuracy: 0.9579 - val_loss: 0.5386 - val_accuracy: 0.8934
Epoch 11/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1014 - accuracy: 0.9610 - val_loss: 0.5184 - val_accuracy: 0.8960
Epoch 12/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.1036 - accuracy: 0.9606 - val_loss: 0.5307 - val_accuracy: 0.8950
Epoch 13/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0959 - accuracy: 0.9631 - val_loss: 0.5213 - val_accuracy: 0.8984
Epoch 14/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0980 - accuracy: 0.9628 - val_loss: 0.5649 - val_accuracy: 0.8938
Epoch 15/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0970 - accuracy: 0.9619 - val_loss: 0.5267 - val_accuracy: 0.8944
Epoch 16/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0985 - accuracy: 0.9626 - val_loss: 0.5018 - val_accuracy: 0.8866
Epoch 17/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0911 - accuracy: 0.9661 - val_loss: 0.5079 - val_accuracy: 0.8932
Epoch 18/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0931 - accuracy: 0.9647 - val_loss: 0.5892 - val_accuracy: 0.8980
Epoch 19/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0876 - accuracy: 0.9654 - val_loss: 0.5265 - val_accuracy: 0.8972
Epoch 20/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0887 - accuracy: 0.9659 - val_loss: 0.5949 - val_accuracy: 0.8964
Epoch 21/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0848 - accuracy: 0.9672 - val_loss: 0.5871 - val_accuracy: 0.8864
Epoch 22/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0900 - accuracy: 0.9663 - val_loss: 0.6204 - val_accuracy: 0.8920
Epoch 23/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0783 - accuracy: 0.9697 - val_loss: 0.6181 - val_accuracy: 0.8928
Epoch 24/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0841 - accuracy: 0.9677 - val_loss: 0.6237 - val_accuracy: 0.8956
Epoch 25/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.5921 - val_accuracy: 0.8976
Epoch 26/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0754 - accuracy: 0.9712 - val_loss: 0.6115 - val_accuracy: 0.8972
Epoch 27/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0811 - accuracy: 0.9692 - val_loss: 0.7208 - val_accuracy: 0.8892
Epoch 28/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.7291 - val_accuracy: 0.8898
Epoch 29/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0761 - accuracy: 0.9709 - val_loss: 0.7166 - val_accuracy: 0.8884
Epoch 30/30
1719/1719 [==============================] - 2s 1ms/step - loss: 0.0753 - accuracy: 0.9717 - val_loss: 0.6515 - val_accuracy: 0.8980
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epochs&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;epochs&#39;)
</pre></div>
</div>
<img alt="../_images/MultiLayerPerceptron_21_1.png" src="../_images/MultiLayerPerceptron_21_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>313/313 [==============================] - 0s 1000us/step - loss: 102.3985 - accuracy: 0.8648
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[102.39849090576172, 0.864799976348877]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_new</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_proba</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="saving-and-restoring-a-model">
<h2>4. Saving and restoring a model<a class="headerlink" href="#saving-and-restoring-a-model" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;my_first_NN.h5&quot;</span><span class="p">)</span>
<span class="n">model2</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;my_first_NN.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fine-tuning-of-neural-networks-hyperparameters">
<h2>5. Fine-tuning of Neural Networks Hyperparameters<a class="headerlink" href="#fine-tuning-of-neural-networks-hyperparameters" title="Permalink to this headline">#</a></h2>
<p>Trial and error is a great first step to build some basic intuition around NN and their training. However, a more systematic approach is to search the hyper-parameter space using grid search or randomized searches.
Scikit-learn has modules dedicated to this: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html</a></p>
<p>We will need to bundle our keras-built model into a function callabe by scikit-learn. This is done using the <code class="docutils literal notranslate"><span class="pre">KerasRegressor</span></code> and <code class="docutils literal notranslate"><span class="pre">KerasClassifer</span></code> objects.
More on this later!</p>
<section id="mlp-with-scikit-learn">
<h3>MLP with scikit learn<a class="headerlink" href="#mlp-with-scikit-learn" title="Permalink to this headline">#</a></h3>
<p>There are some basic NN built in scikit learn, you can see below a tutorial. However, it is limited and one would use pytorch or keras or tensorflow to for any moderate to large model training. Here we will use a “sparse” categorical cross entropy. Cross entropy is used in multiclass classification. Categorical is because the classes are exclusive and that we have sparse labels (either 0 or 1).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Below is an exampled of a classification MLP using Scikit learn.</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span><span class="p">,</span> <span class="n">make_circles</span><span class="p">,</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">h</span> <span class="o">=</span> <span class="mf">.02</span>  <span class="c1"># step size in the mesh</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">classifiers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">classifiers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">make_pipeline</span><span class="p">(</span>
        <span class="n">StandardScaler</span><span class="p">(),</span>
        <span class="n">MLPClassifier</span><span class="p">(</span>
            <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
            <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">))</span>
    <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;alpha </span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">+=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">linearly_separable</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_moons</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">make_circles</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">linearly_separable</span><span class="p">]</span>

<span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># iterate over datasets</span>
<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
    <span class="c1"># split into training and test part</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>

    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">.5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">.5</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">.5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">.5</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span>
                         <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>

    <span class="c1"># just plot the dataset first</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span>
    <span class="n">cm_bright</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">,</span> <span class="s1">&#39;#0000FF&#39;</span><span class="p">])</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">classifiers</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="c1"># Plot the training points</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">)</span>
    <span class="c1"># and testing points</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">yy</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># iterate over classifiers</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">clf</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">classifiers</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">classifiers</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

        <span class="c1"># Plot the decision boundary. For that, we will assign a color to each</span>
        <span class="c1"># point in the mesh [x_min, x_max] x [y_min, y_max].</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="s2">&quot;decision_function&quot;</span><span class="p">):</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Put the result into a color plot</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.8</span><span class="p">)</span>

        <span class="c1"># Plot also the training points</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">,</span>
                   <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
        <span class="c1"># and testing points</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">,</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">yy</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="mf">.3</span><span class="p">,</span> <span class="n">yy</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">+</span> <span class="mf">.3</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span><span class="o">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s1">&#39;0&#39;</span><span class="p">),</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">figure</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">.02</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">.98</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/MultiLayerPerceptron_28_0.png" src="../_images/MultiLayerPerceptron_28_0.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Chapter4-DeepLearning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../Chapter3-MachineLearning/logistic_regression.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">3.2 Logistic regression</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="week9_cnn.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4.2 Convolutional Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By eScience Institute, University of Washington<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>